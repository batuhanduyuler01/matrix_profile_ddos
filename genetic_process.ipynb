{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matrixprofile as mp\n",
    "import random\n",
    "import time\n",
    "import os\n",
    "from matplotlib.patches import Rectangle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_ddos(df: pd.DataFrame):\n",
    "    xAxis = list(range(len(df)))\n",
    "    yAxis = df[\"Label\"].to_list()\n",
    "    # Create a figure\n",
    "    fig = plt.figure(figsize=(25,15))\n",
    "    # Add a subplot\n",
    "    ax = fig.add_subplot()\n",
    "\n",
    "    ax.plot(xAxis, yAxis)\n",
    "    rect = Rectangle((7200, 0), 300, 1, facecolor='lightgreen')\n",
    "    ax.add_patch(rect)\n",
    "    rect = Rectangle((3600*3 + 7200 +280, 0), 300, 1, facecolor='lightgreen')\n",
    "    ax.add_patch(rect)\n",
    "    plt.ylabel('Label')\n",
    "    plt.xlabel('Minute')\n",
    "    plt.title('Network Traffic')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset is loaded in 0.11258908299987525 seconds\n"
     ]
    }
   ],
   "source": [
    "def upload_dataset_with_time(path:str):\n",
    "    startingT = time.perf_counter()\n",
    "    veriseti = pd.read_csv(path, low_memory=False)\n",
    "    endingT = time.perf_counter()\n",
    "    print(f\"Dataset is loaded in {endingT - startingT} seconds\")\n",
    "    return veriseti\n",
    "\n",
    "data_path = '../verisetleri/ddos_dataset_on_seconds.csv'\n",
    "syn_benign_df = upload_dataset_with_time(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset is loaded in 0.022799082999881648 seconds\n"
     ]
    }
   ],
   "source": [
    "ntp_path = '../verisetleri/ntp_by_seconds_data.csv'\n",
    "ntp_df = upload_dataset_with_time(ntp_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_ddos(label:int):\n",
    "    if label > 20:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "ntp_df[\"Label\"] = ntp_df[\"Label\"].apply(lambda x: label_ddos(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddos_ntp = ntp_df[ntp_df[\"Label\"] == 1].sample(524).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddos_ntp = ddos_ntp[[*(syn_benign_df.columns)]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "syn_slice_1 = syn_benign_df.iloc[:12000, :].copy()\n",
    "syn_slice_2 = syn_benign_df.iloc[12000:, :].copy()\n",
    "merged_df = pd.concat([syn_slice_1, ddos_ntp ,syn_slice_2], axis = 0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = merged_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_samples_from_dataset(dataset : pd.DataFrame , samples : list):\n",
    "    if (dataset.empty):\n",
    "        raise ValueError(\"Dataset is None!\")\n",
    "\n",
    "    if (samples == None):\n",
    "        raise ValueError(\"sample list is None\")\n",
    "\n",
    "    return dataset.iloc[samples, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "def calculate_classification_report(y_values_df : pd.DataFrame):\n",
    "    if 'y_true' not in y_values_df.columns:\n",
    "        raise ValueError('true vals not included in df')\n",
    "\n",
    "    if 'y_pred' not in y_values_df.columns:\n",
    "        raise ValueError('pred vals not included in df')\n",
    "\n",
    "    return classification_report(y_values_df[\"y_true\"].to_list(), y_values_df[\"y_pred\"].to_list(), output_dict=True)[\"1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtain_y_vals(dataframe:pd.DataFrame, selected_label_list):\n",
    "    df_idxs = list(range(0, len(dataframe)))\n",
    "    for idx in selected_label_list:\n",
    "        df_idxs.remove(idx)\n",
    "    \n",
    "    pred_df = pd.DataFrame()\n",
    "    pred_df['y_true'] = dataframe[\"Label\"].copy()\n",
    "    pred_df[\"y_pred\"] = dataframe[\"Label\"].copy()\n",
    "    \n",
    "    pred_df.iloc[df_idxs, 0] = 0\n",
    "    pred_df.iloc[selected_label_list, 0] = 1\n",
    "    return pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import stumpy\n",
    "stumpy.config.STUMPY_EXCL_ZONE_DENOM = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[[\"Label\"]]\n",
    "X = df.drop([\"Label\"], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_map = {i : feat_name for i, feat_name in enumerate(X.columns)}\n",
    "X.columns = list(range(0, len(X.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "featureNumber = 5\n",
    "genes = [random.randrange(0,2) for _ in range(featureNumber)]\n",
    "gene_indexes = [idx for idx, f in enumerate(genes) if f == 1]\n",
    "individual = X.iloc[:, gene_indexes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 60\n",
    "curr_mps, curr_indices = stumpy.mstump(individual, window_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5278085.0</td>\n",
       "      <td>1090202.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3508037.0</td>\n",
       "      <td>771278.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3365823.0</td>\n",
       "      <td>755249.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5278085.0</td>\n",
       "      <td>1090202.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3508037.0</td>\n",
       "      <td>771278.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25671</th>\n",
       "      <td>3508037.0</td>\n",
       "      <td>771278.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25672</th>\n",
       "      <td>3365823.0</td>\n",
       "      <td>755249.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25673</th>\n",
       "      <td>5278085.0</td>\n",
       "      <td>1090202.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25674</th>\n",
       "      <td>3508037.0</td>\n",
       "      <td>771278.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25675</th>\n",
       "      <td>3365823.0</td>\n",
       "      <td>755249.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25676 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               2          4\n",
       "0      5278085.0  1090202.0\n",
       "1      3508037.0   771278.0\n",
       "2      3365823.0   755249.0\n",
       "3      5278085.0  1090202.0\n",
       "4      3508037.0   771278.0\n",
       "...          ...        ...\n",
       "25671  3508037.0   771278.0\n",
       "25672  3365823.0   755249.0\n",
       "25673  5278085.0  1090202.0\n",
       "25674  3508037.0   771278.0\n",
       "25675  3365823.0   755249.0\n",
       "\n",
       "[25676 rows x 2 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "individual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ileride sadece discord base mp_maximization kullanirsak ise yarayabilir.\n",
    "import matrixprofile as mp\n",
    "mp_mp = mp.compute(individual[2].to_list(),windows=60, n_jobs=4)\n",
    "mp_mps, mp_pi = mp_mp['mp'], mp_mp['pi']\n",
    "sorted_list = sorted(zip(mp_pi, mp_mps), key=lambda x:x[1], reverse=True)[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 25617)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "curr_mps.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_discords(mps: np.array, individual:pd.DataFrame, window_size:int, discord_num:int=476):\n",
    "    from collections import Counter\n",
    "    curr_mps_dict = dict()\n",
    "    curr_mps_dict = {f_idx: np.argsort(curr_mps[idx])[::-1][:500] for idx, f_idx in enumerate(individual.columns)}\n",
    "    discords = {}\n",
    "    for idx, indices in curr_mps_dict.items():\n",
    "        print(f'now processing current idx: {idx}') \n",
    "        indice_list = []\n",
    "        for indice in indices:\n",
    "            #get mp point window\n",
    "            indice_list.extend(list(range(indice, indice + window_size - 1)))\n",
    "        #sort the indices by count\n",
    "        sorted_discords = sorted(Counter(indice_list).items(), key=lambda t:t[1], reverse=True)\n",
    "        sorted_discord_indexes = [elem[0] for elem in sorted_discords[:discord_num]]\n",
    "\n",
    "        discords[idx] = sorted_discord_indexes\n",
    "    return discords\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def majority_vote_discords(discord_dict: dict, discord_number:int = 476):\n",
    "    from collections import Counter\n",
    "    overall_list = []\n",
    "    for ft, ids_list in discord_dict.items():\n",
    "        overall_list.extend(ids_list.copy())\n",
    "\n",
    "    sorted_overall = (sorted(Counter(overall_list).items(), key=lambda t:t[1], reverse=True))\n",
    "    overall_ids = [elem[0] for elem in sorted_overall[:discord_number]]\n",
    "\n",
    "    return overall_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now processing current idx: 2\n",
      "now processing current idx: 4\n"
     ]
    }
   ],
   "source": [
    "discord_dict = calculate_discords(curr_mps, individual.copy(), window_size=window_size, discord_num=476)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "discords = majority_vote_discords(discord_dict=discord_dict, discord_number=476)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_vals = obtain_y_vals(df.copy(), discords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9978991596638656"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_classification_report(y_vals)['f1-score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2500x1500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_ddos(df.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import stumpy\n",
    "import random\n",
    "\n",
    "class MatrixProfileManager:\n",
    "    if 'global_df' not in dir():\n",
    "        global_df = pd.read_csv('../verisetleri/ddos_dataset_on_seconds.csv', low_memory=True)\n",
    "\n",
    "    THRESHOLD_BASE_ACTIVE = False\n",
    "    threshold = 1.5\n",
    "\n",
    "    def __init__(self, df:pd.DataFrame, window_size:int = 60, discord_number = 476, method='mpx', measure='acc'):\n",
    "        self.measurement = measure\n",
    "        self.window_size = window_size\n",
    "        self.discord_number = discord_number\n",
    "        self.discord_dict = {}\n",
    "        self.discords = []\n",
    "        self.df = df\n",
    "        self.mp_method = method\n",
    "        self.curr_mp_dict = {}\n",
    "\n",
    "    def calculate_mp_multivariate_stumpy(self):\n",
    "        curr_mps, curr_indices = stumpy.mstump(self.df, self.window_size)\n",
    "        self.mps = curr_mps\n",
    "\n",
    "    def calculate_mp_seperately_mpx(self):\n",
    "        import matrixprofile as mp\n",
    "        mp_list = []\n",
    "        \n",
    "        for ft in self.df.columns:\n",
    "            inputSignal = self.df[ft].to_list()\n",
    "            matrix_profile = mp.compute(inputSignal, windows=self.window_size, threshold=0.95, n_jobs=4)\n",
    "            mp_list.append(matrix_profile['mp'])\n",
    "\n",
    "        self.mps = np.array(mp_list)\n",
    "    \n",
    "    def calculate_discords(self):\n",
    "        from collections import Counter\n",
    "        curr_mps_dict = dict()\n",
    "        curr_mps_dict = {f_idx: np.argsort(self.mps[idx])[::-1][:1000] for idx, f_idx in enumerate(self.df.columns)}\n",
    "        self.curr_mp_dict = {f_idx: np.sort(self.mps[idx])[::-1][:self.discord_number] for idx, f_idx in enumerate(self.df.columns)}\n",
    "\n",
    "        for idx, indices in curr_mps_dict.items():\n",
    "            # print(f'now processing current idx: {idx}') \n",
    "            indice_list = []\n",
    "            for indice in indices:\n",
    "                #get mp point window\n",
    "                indice_list.extend(list(range(indice, indice + self.window_size - 1)))\n",
    "            #sort the indices by count\n",
    "            sorted_discords = sorted(Counter(indice_list).items(), key=lambda t:t[1], reverse=True)\n",
    "            sorted_discord_indexes = [elem[0] for elem in sorted_discords[:self.discord_number]]\n",
    "\n",
    "            self.discord_dict[idx] = sorted_discord_indexes\n",
    "\n",
    "    def majority_vote_discords(self):\n",
    "        from collections import Counter\n",
    "        overall_list = []\n",
    "        for ft, ids_list in self.discord_dict.items():\n",
    "            overall_list.extend(ids_list.copy())\n",
    "\n",
    "        if (MatrixProfileManager.THRESHOLD_BASE_ACTIVE):\n",
    "            self.discords = list(set(overall_list)).copy()\n",
    "            return\n",
    "\n",
    "        sorted_overall = (sorted(Counter(overall_list).items(), key=lambda t:t[1], reverse=True))\n",
    "        self.discords = [elem[0] for elem in sorted_overall[:self.discord_number]]\n",
    "\n",
    "\n",
    "    def obtain_y_vals(self):\n",
    "        df_idxs = list(range(0, len(MatrixProfileManager.global_df)))\n",
    "        for idx in self.discords:\n",
    "            df_idxs.remove(idx)\n",
    "  \n",
    "        \n",
    "        self.pred_df = pd.DataFrame()\n",
    "        self.pred_df['y_true'] = MatrixProfileManager.global_df[\"Label\"].copy()\n",
    "        self.pred_df[\"y_pred\"] = MatrixProfileManager.global_df[\"Label\"].copy()\n",
    "        \n",
    "        self.pred_df.iloc[df_idxs, 0] = 0\n",
    "        self.pred_df.iloc[self.discords, 0] = 1\n",
    "\n",
    "    def calculate_classification_report(self):\n",
    "        from sklearn.metrics import classification_report\n",
    "        if 'y_true' not in self.pred_df.columns:\n",
    "            raise ValueError('true vals not included in df')\n",
    "\n",
    "        if 'y_pred' not in self.pred_df.columns:\n",
    "            raise ValueError('pred vals not included in df')\n",
    "\n",
    "        self.creport = classification_report(self.pred_df[\"y_true\"].to_list(),\n",
    "                                             self.pred_df[\"y_pred\"].to_list(), output_dict=True)[\"1\"]\n",
    "\n",
    "    def get_f1_score(self):\n",
    "        if self.creport is None:\n",
    "            raise ValueError('Classification Report is not ready!')\n",
    "            \n",
    "        return self.creport['f1-score']\n",
    "\n",
    "    def get_mp_score(self):\n",
    "        #maximize this\n",
    "        return sum([sum(mp_score) for mp_score in self.curr_mp_dict.values()]) / len(self.curr_mp_dict.keys())\n",
    "\n",
    "    def calculate_cost(self):\n",
    "        if self.mp_method.lower() == 'mpx':\n",
    "            self.calculate_mp_seperately_mpx()\n",
    "        else:\n",
    "            self.calculate_mp_multivariate_stumpy()\n",
    "        \n",
    "        self.calculate_discords()\n",
    "        self.majority_vote_discords()\n",
    "        self.obtain_y_vals()\n",
    "        self.calculate_classification_report()\n",
    "\n",
    "        f1_score = self.get_f1_score()\n",
    "        mp_score = self.get_mp_score()\n",
    "        return mp_score, f1_score\n",
    "\n",
    "    def calculate_thresholded_discords(self):\n",
    "        from collections import Counter\n",
    "        curr_mps_dict = dict()\n",
    "        threshold = MatrixProfileManager.threshold\n",
    "        curr_mps_dict = {f_idx: np.where(self.mps[idx] > threshold)[0].tolist() for idx, f_idx in enumerate(self.df.columns)}\n",
    "        self.curr_mp_dict = {f_idx: np.sort(self.mps[idx])[::-1][:10] for idx, f_idx in enumerate(self.df.columns)}\n",
    "\n",
    "        for idx, indices in curr_mps_dict.items():\n",
    "            # print(f'now processing current idx: {idx}') \n",
    "            indice_list = []\n",
    "            for indice in indices:\n",
    "                #get mp point window\n",
    "                indice_list.extend(list(range(indice, indice + self.window_size - 1)))\n",
    "\n",
    "            if (MatrixProfileManager.THRESHOLD_BASE_ACTIVE):\n",
    "                self.discord_dict[idx] = indice_list.copy()\n",
    "            else:\n",
    "                AssertionError(\"wrong func!\")\n",
    "\n",
    "    def calculate_threshold_based_cost(self):    \n",
    "        if self.mp_method.lower() == 'mpx':\n",
    "            self.calculate_mp_seperately_mpx()\n",
    "        else:\n",
    "            self.calculate_mp_multivariate_stumpy()\n",
    "\n",
    "        self.calculate_thresholded_discords()\n",
    "        self.majority_vote_discords()\n",
    "        self.obtain_y_vals()\n",
    "        self.calculate_classification_report()\n",
    "\n",
    "        f1_score = self.get_f1_score()\n",
    "        mp_score = self.get_mp_score()\n",
    "        return mp_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "MatrixProfileManager.global_df = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(83.23035341389235, 0.6386349786715417)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class GeneticAlgo:\n",
    "    verbosity_level = 0\n",
    "    def __init__(self, df:pd.DataFrame, max_features:int, population_bag_size:int = 3, fitness = 'MP'):\n",
    "        print('Genetic Algorithm Process is ready to start')\n",
    "        self.df = df.copy()\n",
    "        self.y = df[[\"Label\"]]\n",
    "        self.X = df.drop([\"Label\"], axis = 1)\n",
    "        self.feature_map = {i : feat_name for i, feat_name in enumerate(self.X.columns)}\n",
    "        self.X.columns = list(range(0, len(self.X.columns)))\n",
    "        self.feature_number = max_features\n",
    "        self.pop_bag_size = population_bag_size\n",
    "        self.creport = None\n",
    "        self.eval_result = None\n",
    "        self.fitness_type = fitness\n",
    "        \n",
    "\n",
    "    def initialize_population(self):\n",
    "        self.population_bag = []\n",
    "        for _ in range(self.pop_bag_size):\n",
    "            #0 veya 1 atiyoruz feature pick or not pick, 1 olanlari appendliyoruz.\n",
    "            genes = [random.randrange(0,2) for _ in range(self.feature_number)]\n",
    "            gene_indexes = [idx for idx, f in enumerate(genes) if f == 1]\n",
    "            if (len(gene_indexes) == 0):\n",
    "                gene_indexes.append(random.randint(1,self.feature_number))\n",
    "\n",
    "            self.population_bag.append(self.X.iloc[:, gene_indexes])\n",
    "\n",
    "        return self.population_bag\n",
    "\n",
    "    def create_population(self, pop_bag) -> pd.DataFrame:\n",
    "        self.population_bag.clear()\n",
    "        for elem in pop_bag:\n",
    "            self.population_bag.append(self.X.iloc[:, elem])\n",
    "            \n",
    "        return self.population_bag\n",
    "\n",
    "    def fitness_function(self, individual:pd.DataFrame):\n",
    "        mp_manager = MatrixProfileManager(individual, window_size=60, discord_number=1000, method='mpx', measure='mp')\n",
    "        cost, f1_score = mp_manager.calculate_cost()\n",
    "        if (GeneticAlgo.verbosity_level < 2):\n",
    "            print(f'processing solution: {individual.columns.to_list()}')\n",
    "            print(f\"f1-score is: {mp_manager.get_f1_score()}\")\n",
    "        #return f1score instead of cost in order to maximize f1-score:\n",
    "        \n",
    "        # return cost, f1_score\n",
    "        return cost, f1_score\n",
    "\n",
    "    def eval_fit_population(self, pop_bag):\n",
    "        #This evaluation is based on minimizing the cost!\n",
    "        result = {}\n",
    "        fit_vals_lst = []\n",
    "        f1_score_lst = []\n",
    "        solutions = []\n",
    "        for individual in pop_bag:\n",
    "            if (type(individual) != pd.DataFrame):\n",
    "                assert(True)\n",
    "\n",
    "            cost, f1_sc = self.fitness_function(individual.copy())\n",
    "            fit_vals_lst.append(cost)\n",
    "            f1_score_lst.append(f1_sc)\n",
    "            solutions.append(individual.columns.to_list())\n",
    "            \n",
    "        result[\"fit_vals\"] = fit_vals_lst\n",
    "        result[\"f1-scores\"] = f1_score_lst \n",
    "        if self.fitness_type == \"MP\":\n",
    "            min_wgh = [abs(np.min(list(result['fit_vals'])) - i) for i in list(result['fit_vals'])]\n",
    "        else:\n",
    "            min_wgh = [abs(np.min(list(result['f1-scores'])) - i) for i in list(result['f1-scores'])]\n",
    "        \n",
    "        from scipy.special import logsumexp\n",
    "        result[\"fit_wgh\"]  = [i/logsumexp(min_wgh) for i in min_wgh]\n",
    "        result[\"solution\"] = np.array(solutions, dtype=list).tolist()\n",
    "        \n",
    "        self.eval_result = result.copy()\n",
    "        return result\n",
    "\n",
    "    def find_best(self, eval_result:dict)->dict:\n",
    "        # Best individual so far\n",
    "        best_fit = np.max(eval_result[\"fit_vals\"])\n",
    "        best_fit_index = eval_result[\"fit_vals\"].index(best_fit)\n",
    "        best_solution  = eval_result[\"solution\"][best_fit_index]\n",
    "        f1_sc = eval_result[\"f1-scores\"][best_fit_index]\n",
    "        print(f'best fit: {best_fit}\\nsolution: {best_solution}\\nf1Score: {f1_sc}')\n",
    "        return {'best_fit': best_fit, 'index' : best_fit_index,\n",
    "                 'solution': best_solution, 'f1-score' : f1_sc}\n",
    "\n",
    "    def pick_one(self, pop_bag):\n",
    "        \n",
    "        if self.eval_result is None:\n",
    "            eval_result = self.eval_fit_population(pop_bag)\n",
    "        else:\n",
    "            eval_result = self.eval_result\n",
    "\n",
    "        notPicked=True\n",
    "        cnt = 0\n",
    "        pickedSol = list()\n",
    "        while (notPicked == True):\n",
    "            rnIndex = random.randint(0, len(pop_bag)-1)\n",
    "            rnPick  = eval_result[\"fit_wgh\"][rnIndex]\n",
    "            r = random.random()\n",
    "            if  r <= rnPick:\n",
    "                pickedSol = eval_result[\"solution\"][rnIndex]\n",
    "                notPicked = False\n",
    "            if (cnt > 250):\n",
    "                pickedSol = eval_result[\"solution\"][rnIndex]\n",
    "                notPicked = False\n",
    "            cnt += 1\n",
    "\n",
    "        return pickedSol\n",
    "\n",
    "    def crossover(self, solA, solB):\n",
    "        \n",
    "        n     = len(solA)\n",
    "        child: list = []\n",
    "\n",
    "        num_els = random.randint(0, self.feature_number)\n",
    "        str_pnt = random.randint(0, max(0,n-3))\n",
    "        end_pnt = n if int(str_pnt+num_els) > n else int(str_pnt+num_els)\n",
    "\n",
    "        blockA = list(solA[str_pnt:end_pnt])\n",
    "        child = blockA.copy()\n",
    "\n",
    "        for elem in solB:\n",
    "            if len(child) >= num_els:\n",
    "                break\n",
    "            if elem not in blockA:\n",
    "                child.append(elem)  \n",
    "\n",
    "        if (len(child) < 1):\n",
    "            return solA\n",
    "\n",
    "        return child\n",
    "\n",
    "    def mutation(self,sol):\n",
    "        \n",
    "        n = len(sol)\n",
    "        pos_1 = random.randint(0,n-1)\n",
    "        pos_2 = random.randint(0,n-1)\n",
    "        result = self.swap(sol, pos_1, pos_2)\n",
    "        return result\n",
    "\n",
    "    def swap(self,sol, posA, posB):\n",
    "        result = sol.copy()\n",
    "        elA = sol[posA]\n",
    "        elB = sol[posB]\n",
    "        result[posA] = elB\n",
    "        result[posB] = elA\n",
    "        return result"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imply Genetic Process with MP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mp_genetic_utils\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def func(generation_num:int=5, max_feat:int=20, pop_bag_size:int=10, fitness_type:str=\"MP\"):\n",
    "    import random as rnd\n",
    "    GeneticAlgo.verbosity_level = 4\n",
    "    genetic_algo = GeneticAlgo(df.copy(), max_features=max_feat, population_bag_size=pop_bag_size, fitness=fitness_type)\n",
    "    pop_bag = genetic_algo.initialize_population()\n",
    "    generation_number = generation_num\n",
    "    for generation in range(generation_number):\n",
    "        print(f\"Generation {generation} is started!\")\n",
    "        \n",
    "        res = genetic_algo.eval_fit_population(pop_bag)\n",
    "        best_fit, _, best_solution, f1_score = genetic_algo.find_best(res).values()\n",
    "        \n",
    "        if (generation == 0):\n",
    "            best_fit_global      = best_fit\n",
    "            best_solution_global = best_solution\n",
    "        else:\n",
    "            if (best_fit >= best_fit_global):\n",
    "                best_fit_global      = best_fit\n",
    "                best_solution_global = best_solution\n",
    "\n",
    "        new_pop_bag = []\n",
    "        for i in range(len(genetic_algo.population_bag)):\n",
    "                # Pick 2 parents from the bag\n",
    "            pA = genetic_algo.pick_one(pop_bag)\n",
    "            pB = genetic_algo.pick_one(pop_bag)\n",
    "            new_element = pA\n",
    "            # Crossover the parents\n",
    "            if rnd.random() <= 0.87:\n",
    "                new_element = genetic_algo.crossover(pA, pB)\n",
    "            # Mutate the child\n",
    "            # if rnd.random() <= 0.7:\n",
    "            #     new_element = mutation(new_element) \n",
    "            \n",
    "            # Append the child to the bag\n",
    "            new_pop_bag.append(new_element)\n",
    "            # Set the new bag as the population bag\n",
    "        pop_bag = genetic_algo.create_population(new_pop_bag)\n",
    "\n",
    "    print(\"\\n\\n**** Generations Over ****\\n\")\n",
    "    print(f\"Best Fitness: {best_fit_global}\")\n",
    "    print(f\"Best Solution: {best_solution_global}\")\n",
    "    print(f\"F1-Score: {f1_score}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Genetic Algorithm Process is ready to start\n",
      "Generation 0 is started!\n",
      "best fit: 3580.4160764984167\n",
      "solution: [1, 2, 5, 6, 7, 8, 11, 16, 17, 19]\n",
      "f1Score: 0.937\n",
      "Generation 1 is started!\n",
      "best fit: 3658.6889976097445\n",
      "solution: [15, 16, 19, 0, 1, 2, 6]\n",
      "f1Score: 0.902\n",
      "Generation 2 is started!\n",
      "best fit: 3733.0474950371035\n",
      "solution: [4, 5, 11, 12, 15, 16, 19, 0, 1, 2, 6]\n",
      "f1Score: 0.936\n",
      "Generation 3 is started!\n",
      "best fit: 3733.047495037103\n",
      "solution: [16, 19, 0, 1, 2, 6, 4, 5, 11, 12, 15]\n",
      "f1Score: 0.914\n",
      "Generation 4 is started!\n",
      "best fit: 4061.484399021706\n",
      "solution: [4, 5, 12, 15, 0, 2, 6, 16]\n",
      "f1Score: 0.8769999999999999\n",
      "\n",
      "\n",
      "**** Generations Over ****\n",
      "\n",
      "Best Fitness: 4061.484399021706\n",
      "Best Solution: [4, 5, 12, 15, 0, 2, 6, 16]\n",
      "F1-Score: 0.8769999999999999\n"
     ]
    }
   ],
   "source": [
    "MatrixProfileManager.global_df = df.copy()\n",
    "func(fitness_type=\"MP\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function func in module __main__:\n",
      "\n",
      "func(generation_num: int = 5, max_feat: int = 20, pop_bag_size: int = 10, fitness_type: str = 'MP')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Genetic Algorithm Process is ready to start\n",
      "Generation 0 is started!\n",
      "best fit: 4287.18390427637\n",
      "solution: [0, 4, 6, 7, 8, 9, 10, 14, 16, 17, 19, 21, 24, 27, 28, 29, 30, 31, 32, 33]\n",
      "f1Score: 0.911\n",
      "Generation 1 is started!\n",
      "best fit: 4647.944506777544\n",
      "solution: [15, 16, 19, 20, 21, 26, 27, 28, 32, 35, 36, 1]\n",
      "f1Score: 0.7190000000000001\n",
      "Generation 2 is started!\n",
      "best fit: 4728.889181809727\n",
      "solution: [23, 24, 25, 28, 32, 33, 36, 29, 31, 35]\n",
      "f1Score: 0.861\n",
      "Generation 3 is started!\n",
      "best fit: 5613.526101977333\n",
      "solution: [1, 4, 5, 6, 27]\n",
      "f1Score: 0.933\n",
      "Generation 4 is started!\n",
      "best fit: 6179.841304820825\n",
      "solution: [28, 32, 35, 36]\n",
      "f1Score: 0.75\n",
      "Generation 5 is started!\n",
      "best fit: 5828.204952309163\n",
      "solution: [28, 32, 33, 36, 29, 7, 8]\n",
      "f1Score: 0.598\n",
      "Generation 6 is started!\n",
      "best fit: 6093.506316600381\n",
      "solution: [25, 28, 32]\n",
      "f1Score: 0.637\n",
      "Generation 7 is started!\n",
      "best fit: 4744.031902301571\n",
      "solution: [5, 6]\n",
      "f1Score: 0.524\n",
      "Generation 8 is started!\n",
      "best fit: 5019.651260697574\n",
      "solution: [37, 0, 11, 14, 32, 36, 29]\n",
      "f1Score: 0.778\n",
      "Generation 9 is started!\n",
      "best fit: 4273.32406269018\n",
      "solution: [24, 32, 35, 36, 5, 6, 7, 8, 9, 17, 28, 33]\n",
      "f1Score: 0.933\n",
      "Generation 10 is started!\n",
      "best fit: 3901.302833400731\n",
      "solution: [23, 24, 25, 1, 7, 3, 10, 32, 33, 36, 29, 5, 6, 8]\n",
      "f1Score: 0.937\n",
      "Generation 11 is started!\n",
      "best fit: 4232.970918320685\n",
      "solution: [10, 32, 33, 36, 29, 5, 6, 8, 7, 9, 17, 28, 24, 23, 25, 3]\n",
      "f1Score: 0.937\n",
      "Generation 12 is started!\n",
      "best fit: 3838.949285199426\n",
      "solution: [25, 1, 7, 3, 10, 32, 33, 36, 29, 5, 6, 8, 17, 23, 24]\n",
      "f1Score: 0.937\n",
      "Generation 13 is started!\n",
      "best fit: 4146.1401789138645\n",
      "solution: [7, 17, 23, 24, 25, 1, 3, 10, 32, 33, 36, 29, 5, 6, 8, 28, 9]\n",
      "f1Score: 0.937\n",
      "Generation 14 is started!\n",
      "best fit: 4232.970918320685\n",
      "solution: [7, 3, 10, 32, 33, 36, 29, 5, 6, 8, 17, 23, 24, 25, 9, 28]\n",
      "f1Score: 0.937\n",
      "Generation 15 is started!\n",
      "best fit: 4351.856512681908\n",
      "solution: [3, 6, 7, 8, 9, 17, 28, 33, 24, 10, 32, 36, 29, 5, 14]\n",
      "f1Score: 0.935\n",
      "Generation 16 is started!\n",
      "best fit: 5169.471411659404\n",
      "solution: [29, 5, 14, 10, 32]\n",
      "f1Score: 0.55\n",
      "Generation 17 is started!\n",
      "best fit: 4351.856512681908\n",
      "solution: [10, 32, 3, 6, 7, 8, 9, 17, 28, 33, 24, 36, 29, 5, 14]\n",
      "f1Score: 0.935\n",
      "Generation 18 is started!\n",
      "best fit: 4679.780522527152\n",
      "solution: [24, 36, 29, 5, 14, 3]\n",
      "f1Score: 0.933\n",
      "Generation 19 is started!\n",
      "best fit: 4679.780522527152\n",
      "solution: [36, 29, 5, 14, 3, 24]\n",
      "f1Score: 0.935\n",
      "\n",
      "\n",
      "**** Generations Over ****\n",
      "\n",
      "Best Fitness: 6179.841304820825\n",
      "Best Solution: [28, 32, 35, 36]\n",
      "F1-Score: 0.935\n"
     ]
    }
   ],
   "source": [
    "func(generation_num=20, max_feat=38, pop_bag_size=10, fitness_type=\"F1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where(mp_mng.mps[4] > 1.5)[0].shape\n",
    "discords = np.where(mp_mng.mps[4] > 5)[0].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "95"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(df.iloc[discords, -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "batu_discords = (np.argsort(mp_mng.mps[4])[::-1][:1000]).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.919"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(df.iloc[batu_discords, -1]) / 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import stumpy\n",
    "import random\n",
    "\n",
    "class MatrixProfileManager:\n",
    "    if 'global_df' not in dir():\n",
    "        global_df = pd.read_csv('../verisetleri/ddos_dataset_on_seconds.csv', low_memory=True)\n",
    "\n",
    "    THRESHOLD_BASE_ACTIVE = False\n",
    "    threshold = 10\n",
    "\n",
    "    def __init__(self, df:pd.DataFrame, window_size:int = 60, discord_number = 476, method='mpx', measure='acc'):\n",
    "        self.measurement = measure\n",
    "        self.window_size = window_size\n",
    "        self.discord_number = discord_number\n",
    "        self.discord_dict = {}\n",
    "        self.discords = []\n",
    "        self.df = df\n",
    "        self.mp_method = method\n",
    "        self.curr_mp_dict = {}\n",
    "\n",
    "    def calculate_mp_multivariate_stumpy(self):\n",
    "        curr_mps, curr_indices = stumpy.mstump(self.df, self.window_size)\n",
    "        self.mps = curr_mps\n",
    "\n",
    "    def calculate_mp_seperately_mpx(self):\n",
    "        import matrixprofile as mp\n",
    "        mp_list = []\n",
    "        \n",
    "        for ft in self.df.columns:\n",
    "            inputSignal = self.df[ft].to_list()\n",
    "            matrix_profile = mp.compute(inputSignal, windows=self.window_size, threshold=0.95, n_jobs=4)\n",
    "            mp_list.append(matrix_profile['mp'])\n",
    "\n",
    "        self.mps = np.array(mp_list)\n",
    "    \n",
    "    def calculate_discords(self):\n",
    "        from collections import Counter\n",
    "        curr_mps_dict = dict()\n",
    "        curr_mps_dict = {f_idx: np.argsort(self.mps[idx])[::-1][:1000] for idx, f_idx in enumerate(self.df.columns)}\n",
    "        self.curr_mp_dict = {f_idx: np.sort(self.mps[idx])[::-1][:self.discord_number] for idx, f_idx in enumerate(self.df.columns)}\n",
    "\n",
    "        for idx, indices in curr_mps_dict.items():\n",
    "            # print(f'now processing current idx: {idx}') \n",
    "            indice_list = []\n",
    "            for indice in indices:\n",
    "                #get mp point window\n",
    "                indice_list.extend(list(range(indice, indice + self.window_size - 1)))\n",
    "            #sort the indices by count\n",
    "            sorted_discords = sorted(Counter(indice_list).items(), key=lambda t:t[1], reverse=True)\n",
    "            sorted_discord_indexes = [elem[0] for elem in sorted_discords[:self.discord_number]]\n",
    "\n",
    "            self.discord_dict[idx] = sorted_discord_indexes\n",
    "\n",
    "    def majority_vote_discords(self):\n",
    "        from collections import Counter\n",
    "        overall_list = []\n",
    "        for ft, ids_list in self.discord_dict.items():\n",
    "            overall_list.extend(ids_list.copy())\n",
    "\n",
    "        if (MatrixProfileManager.THRESHOLD_BASE_ACTIVE):\n",
    "            self.discords = list(set(overall_list)).copy()\n",
    "            return\n",
    "\n",
    "        sorted_overall = (sorted(Counter(overall_list).items(), key=lambda t:t[1], reverse=True))\n",
    "        self.discords = [elem[0] for elem in sorted_overall[:self.discord_number]]\n",
    "\n",
    "\n",
    "    def obtain_y_vals(self):\n",
    "        df_idxs = list(range(0, len(MatrixProfileManager.global_df)))\n",
    "        print(self.discords)\n",
    "        for idx in self.discords:\n",
    "            df_idxs.remove(idx)\n",
    "  \n",
    "        \n",
    "        self.pred_df = pd.DataFrame()\n",
    "        self.pred_df['y_true'] = MatrixProfileManager.global_df[\"Label\"].copy()\n",
    "        self.pred_df[\"y_pred\"] = MatrixProfileManager.global_df[\"Label\"].copy()\n",
    "        \n",
    "        self.pred_df.iloc[df_idxs, 0] = 0\n",
    "        self.pred_df.iloc[self.discords, 0] = 1\n",
    "\n",
    "    def calculate_classification_report(self):\n",
    "        from sklearn.metrics import classification_report\n",
    "        if 'y_true' not in self.pred_df.columns:\n",
    "            raise ValueError('true vals not included in df')\n",
    "\n",
    "        if 'y_pred' not in self.pred_df.columns:\n",
    "            raise ValueError('pred vals not included in df')\n",
    "\n",
    "        self.creport = classification_report(self.pred_df[\"y_true\"].to_list(),\n",
    "                                             self.pred_df[\"y_pred\"].to_list(), output_dict=True)[\"1\"]\n",
    "\n",
    "    def get_f1_score(self):\n",
    "        if self.creport is None:\n",
    "            raise ValueError('Classification Report is not ready!')\n",
    "            \n",
    "        return self.creport['f1-score']\n",
    "\n",
    "    def get_mp_score(self):\n",
    "        #maximize this\n",
    "        return sum([sum(mp_score) for mp_score in self.curr_mp_dict.values()]) / len(self.curr_mp_dict.keys())\n",
    "\n",
    "    def calculate_cost(self):\n",
    "        if self.mp_method.lower() == 'mpx':\n",
    "            self.calculate_mp_seperately_mpx()\n",
    "        else:\n",
    "            self.calculate_mp_multivariate_stumpy()\n",
    "        \n",
    "        self.calculate_discords()\n",
    "        self.majority_vote_discords()\n",
    "        self.obtain_y_vals()\n",
    "        self.calculate_classification_report()\n",
    "\n",
    "        f1_score = self.get_f1_score()\n",
    "        mp_score = self.get_mp_score()\n",
    "        return mp_score, f1_score\n",
    "\n",
    "    def calculate_thresholded_discords(self):\n",
    "        from collections import Counter\n",
    "        curr_mps_dict = dict()\n",
    "        threshold = MatrixProfileManager.threshold\n",
    "        curr_mps_dict = {f_idx: np.where(self.mps[idx] > threshold)[0].tolist() for idx, f_idx in enumerate(self.df.columns)}\n",
    "        self.curr_mp_dict = {f_idx: np.sort(self.mps[idx])[::-1][:10] for idx, f_idx in enumerate(self.df.columns)}\n",
    "\n",
    "        for idx, indices in curr_mps_dict.items():\n",
    "            # print(f'now processing current idx: {idx}') \n",
    "            indice_list = []\n",
    "            for indice in indices:\n",
    "                #get mp point window\n",
    "                indice_list.extend(list(range(indice, indice + self.window_size - 1)))\n",
    "\n",
    "            if (MatrixProfileManager.THRESHOLD_BASE_ACTIVE):\n",
    "                self.discord_dict[idx] = indice_list.copy()\n",
    "            else:\n",
    "                AssertionError(\"wrong func!\")\n",
    "\n",
    "    def calculate_threshold_based_cost(self):    \n",
    "        if self.mp_method.lower() == 'mpx':\n",
    "            self.calculate_mp_seperately_mpx()\n",
    "        else:\n",
    "            self.calculate_mp_multivariate_stumpy()\n",
    "\n",
    "        self.calculate_thresholded_discords()\n",
    "        self.majority_vote_discords()\n",
    "        self.obtain_y_vals()\n",
    "        self.calculate_classification_report()\n",
    "\n",
    "        f1_score = self.get_f1_score()\n",
    "        mp_score = self.get_mp_score()\n",
    "        return mp_score, f1_score\n",
    "\n",
    "\n",
    "class GeneticAlgo:\n",
    "    verbosity_level = 0\n",
    "    thresholded_mp = False\n",
    "    def __init__(self, df:pd.DataFrame, max_features:int, population_bag_size:int = 3, fitness = 'MP'):\n",
    "        print('Genetic Algorithm Process is ready to start')\n",
    "        self.df = df.copy()\n",
    "        self.y = df[[\"Label\"]]\n",
    "        self.X = df.drop([\"Label\"], axis = 1)\n",
    "        self.feature_map = {i : feat_name for i, feat_name in enumerate(self.X.columns)}\n",
    "        self.X.columns = list(range(0, len(self.X.columns)))\n",
    "        self.feature_number = max_features\n",
    "        self.pop_bag_size = population_bag_size\n",
    "        self.creport = None\n",
    "        self.eval_result = None\n",
    "        self.fitness_type = fitness\n",
    "        \n",
    "\n",
    "    def initialize_population(self):\n",
    "        self.population_bag = []\n",
    "        for _ in range(self.pop_bag_size):\n",
    "            #0 veya 1 atiyoruz feature pick or not pick, 1 olanlari appendliyoruz.\n",
    "            genes = [random.randrange(0,2) for _ in range(self.feature_number)]\n",
    "            gene_indexes = [idx for idx, f in enumerate(genes) if f == 1]\n",
    "            if (len(gene_indexes) == 0):\n",
    "                gene_indexes.append(random.randint(1,self.feature_number))\n",
    "\n",
    "            self.population_bag.append(self.X.iloc[:, gene_indexes])\n",
    "\n",
    "        return self.population_bag\n",
    "\n",
    "    def create_population(self, pop_bag) -> pd.DataFrame:\n",
    "        self.population_bag.clear()\n",
    "        for elem in pop_bag:\n",
    "            self.population_bag.append(self.X.iloc[:, elem])\n",
    "            \n",
    "        return self.population_bag\n",
    "\n",
    "    def fitness_function(self, individual:pd.DataFrame):\n",
    "        if (GeneticAlgo.thresholded_mp == True):\n",
    "            MatrixProfileManager.THRESHOLD_BASE_ACTIVE = True\n",
    "        else:\n",
    "            MatrixProfileManager.THRESHOLD_BASE_ACTIVE = False\n",
    "\n",
    "        mp_manager = MatrixProfileManager(individual, window_size=60, discord_number=1000, method='mpx', measure='f1')\n",
    "        if (GeneticAlgo.thresholded_mp == False):\n",
    "            cost, f1_score = mp_manager.calculate_cost()\n",
    "        elif (GeneticAlgo.thresholded_mp == True):\n",
    "            cost, f1_score = mp_manager.calculate_threshold_based_cost()\n",
    "            \n",
    "        if (GeneticAlgo.verbosity_level < 2):\n",
    "            print(f'processing solution: {individual.columns.to_list()}')\n",
    "            print(f\"f1-score is: {mp_manager.get_f1_score()}\")\n",
    "        #return f1score instead of cost in order to maximize f1-score:\n",
    "        \n",
    "        # return cost, f1_score\n",
    "        return cost, f1_score\n",
    "\n",
    "    def eval_fit_population(self, pop_bag):\n",
    "        #This evaluation is based on minimizing the cost!\n",
    "        result = {}\n",
    "        fit_vals_lst = []\n",
    "        f1_score_lst = []\n",
    "        solutions = []\n",
    "        for individual in pop_bag:\n",
    "            if (type(individual) != pd.DataFrame):\n",
    "                assert(True)\n",
    "\n",
    "            cost, f1_sc = self.fitness_function(individual.copy())\n",
    "            fit_vals_lst.append(cost)\n",
    "            f1_score_lst.append(f1_sc)\n",
    "            solutions.append(individual.columns.to_list())\n",
    "            \n",
    "        result[\"fit_vals\"] = fit_vals_lst\n",
    "        result[\"f1-scores\"] = f1_score_lst \n",
    "        if self.fitness_type == \"MP\":\n",
    "            min_wgh = [abs(np.min(list(result['fit_vals'])) - i) for i in list(result['fit_vals'])]\n",
    "        else:\n",
    "            min_wgh = [abs(np.min(list(result['f1-scores'])) - i) for i in list(result['f1-scores'])]\n",
    "        \n",
    "        from scipy.special import logsumexp\n",
    "        result[\"fit_wgh\"]  = [i/logsumexp(min_wgh) for i in min_wgh]\n",
    "        result[\"solution\"] = np.array(solutions, dtype=list).tolist()\n",
    "        \n",
    "        self.eval_result = result.copy()\n",
    "        return result\n",
    "\n",
    "    def find_best(self, eval_result:dict)->dict:\n",
    "        # Best individual so far\n",
    "        best_fit = np.max(eval_result[\"fit_vals\"])\n",
    "        best_fit_index = eval_result[\"fit_vals\"].index(best_fit)\n",
    "        best_solution  = eval_result[\"solution\"][best_fit_index]\n",
    "        f1_sc = eval_result[\"f1-scores\"][best_fit_index]\n",
    "        print(f'best fit: {best_fit}\\nsolution: {best_solution}\\nf1Score: {f1_sc}')\n",
    "        return {'best_fit': best_fit, 'index' : best_fit_index,\n",
    "                 'solution': best_solution, 'f1-score' : f1_sc}\n",
    "\n",
    "    def pick_one(self, pop_bag):\n",
    "        \n",
    "        if self.eval_result is None:\n",
    "            eval_result = self.eval_fit_population(pop_bag)\n",
    "        else:\n",
    "            eval_result = self.eval_result\n",
    "\n",
    "        notPicked=True\n",
    "        cnt = 0\n",
    "        pickedSol = list()\n",
    "        while (notPicked == True):\n",
    "            rnIndex = random.randint(0, len(pop_bag)-1)\n",
    "            rnPick  = eval_result[\"fit_wgh\"][rnIndex]\n",
    "            r = random.random()\n",
    "            if  r <= rnPick:\n",
    "                pickedSol = eval_result[\"solution\"][rnIndex]\n",
    "                notPicked = False\n",
    "            if (cnt > 250):\n",
    "                pickedSol = eval_result[\"solution\"][rnIndex]\n",
    "                notPicked = False\n",
    "            cnt += 1\n",
    "\n",
    "        return pickedSol\n",
    "\n",
    "    def crossover(self, solA, solB):\n",
    "        \n",
    "        n     = len(solA)\n",
    "        child: list = []\n",
    "\n",
    "        num_els = random.randint(0, self.feature_number)\n",
    "        str_pnt = random.randint(0, max(0,n-3))\n",
    "        end_pnt = n if int(str_pnt+num_els) > n else int(str_pnt+num_els)\n",
    "\n",
    "        blockA = list(solA[str_pnt:end_pnt])\n",
    "        child = blockA.copy()\n",
    "\n",
    "        for elem in solB:\n",
    "            if len(child) >= num_els:\n",
    "                break\n",
    "            if elem not in blockA:\n",
    "                child.append(elem)  \n",
    "\n",
    "        if (len(child) < 1):\n",
    "            return solA\n",
    "\n",
    "        return child\n",
    "\n",
    "    def mutation(self,sol):\n",
    "        \n",
    "        n = len(sol)\n",
    "        pos_1 = random.randint(0,n-1)\n",
    "        pos_2 = random.randint(0,n-1)\n",
    "        result = self.swap(sol, pos_1, pos_2)\n",
    "        return result\n",
    "\n",
    "    def swap(self,sol, posA, posB):\n",
    "        result = sol.copy()\n",
    "        elA = sol[posA]\n",
    "        elB = sol[posB]\n",
    "        result[posA] = elB\n",
    "        result[posB] = elA\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mp_genetic_utils\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def func_thresholded(generation_num:int=5, max_feat:int=20, pop_bag_size:int=10, fitness_type:str=\"MP\"):\n",
    "    import random as rnd\n",
    "    GeneticAlgo.verbosity_level = 4\n",
    "    GeneticAlgo.thresholded_mp = True\n",
    "    genetic_algo = GeneticAlgo(df.copy(), max_features=max_feat, population_bag_size=pop_bag_size, fitness=fitness_type)\n",
    "    pop_bag = genetic_algo.initialize_population()\n",
    "    generation_number = generation_num\n",
    "    for generation in range(generation_number):\n",
    "        print(f\"Generation {generation} is started!\")\n",
    "        \n",
    "        res = genetic_algo.eval_fit_population(pop_bag)\n",
    "        best_fit, _, best_solution, f1_score = genetic_algo.find_best(res).values()\n",
    "        \n",
    "        if (generation == 0):\n",
    "            best_fit_global      = best_fit\n",
    "            best_solution_global = best_solution\n",
    "        else:\n",
    "            if (best_fit >= best_fit_global):\n",
    "                best_fit_global      = best_fit\n",
    "                best_solution_global = best_solution\n",
    "\n",
    "        new_pop_bag = []\n",
    "        for i in range(len(genetic_algo.population_bag)):\n",
    "                # Pick 2 parents from the bag\n",
    "            pA = genetic_algo.pick_one(pop_bag)\n",
    "            pB = genetic_algo.pick_one(pop_bag)\n",
    "            new_element = pA\n",
    "            # Crossover the parents\n",
    "            if rnd.random() <= 0.87:\n",
    "                new_element = genetic_algo.crossover(pA, pB)\n",
    "            # Mutate the child\n",
    "            # if rnd.random() <= 0.7:\n",
    "            #     new_element = mutation(new_element) \n",
    "            \n",
    "            # Append the child to the bag\n",
    "            new_pop_bag.append(new_element)\n",
    "            # Set the new bag as the population bag\n",
    "        pop_bag = genetic_algo.create_population(new_pop_bag)\n",
    "\n",
    "    print(\"\\n\\n**** Generations Over ****\\n\")\n",
    "    print(f\"Best Fitness: {best_fit_global}\")\n",
    "    print(f\"Best Solution: {best_solution_global}\")\n",
    "    print(f\"F1-Score: {f1_score}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "func_thresholded(generation_num=20, max_feat=38, pop_bag_size=10, fitness_type=\"F1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tez_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "284da31d2e08a0f3b9298738c7f12e5d4fd5ac3878570c49a01eae1702b4dd5d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
