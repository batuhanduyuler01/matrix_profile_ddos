{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matrixprofile as mp\n",
    "import random\n",
    "import time\n",
    "import os\n",
    "from matplotlib.patches import Rectangle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_ddos(df: pd.DataFrame):\n",
    "    xAxis = list(range(len(df)))\n",
    "    yAxis = df[\"Label\"].to_list()\n",
    "    # Create a figure\n",
    "    fig = plt.figure(figsize=(25,15))\n",
    "    # Add a subplot\n",
    "    ax = fig.add_subplot()\n",
    "\n",
    "    ax.plot(xAxis, yAxis)\n",
    "    rect = Rectangle((7200, 0), 300, 1, facecolor='lightgreen')\n",
    "    ax.add_patch(rect)\n",
    "    rect = Rectangle((3600*3 + 7200 +280, 0), 300, 1, facecolor='lightgreen')\n",
    "    ax.add_patch(rect)\n",
    "    plt.ylabel('Label')\n",
    "    plt.xlabel('Minute')\n",
    "    plt.title('Network Traffic')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset is loaded in 0.11131854200000024 seconds\n"
     ]
    }
   ],
   "source": [
    "def upload_dataset_with_time(path:str):\n",
    "    startingT = time.perf_counter()\n",
    "    veriseti = pd.read_csv(path, low_memory=False)\n",
    "    endingT = time.perf_counter()\n",
    "    print(f\"Dataset is loaded in {endingT - startingT} seconds\")\n",
    "    return veriseti\n",
    "\n",
    "data_path = '../verisetleri/ddos_dataset_on_seconds.csv'\n",
    "syn_benign_df = upload_dataset_with_time(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset is loaded in 0.01708687500000039 seconds\n"
     ]
    }
   ],
   "source": [
    "ntp_path = '../verisetleri/ntp_by_seconds_data.csv'\n",
    "ntp_df = upload_dataset_with_time(ntp_path)\n",
    "\n",
    "def label_ddos(label:int):\n",
    "    if label > 20:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "ntp_df[\"Label\"] = ntp_df[\"Label\"].apply(lambda x: label_ddos(x))\n",
    "ddos_ntp = ntp_df[ntp_df[\"Label\"] == 1].sample(524).reset_index(drop=True)\n",
    "ddos_ntp = ddos_ntp[[*(syn_benign_df.columns)]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "syn_slice_1 = syn_benign_df.iloc[:12000, :].copy()\n",
    "syn_slice_2 = syn_benign_df.iloc[12000:, :].copy()\n",
    "merged_df = pd.concat([syn_slice_1, ddos_ntp ,syn_slice_2, ddos_ntp], axis = 0).reset_index(drop=True)\n",
    "df = merged_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import stumpy\n",
    "import random\n",
    "\n",
    "class MatrixProfileManager:\n",
    "    if 'global_df' not in dir():\n",
    "        global_df = pd.read_csv('../verisetleri/ddos_dataset_on_seconds.csv', low_memory=True)\n",
    "\n",
    "    THRESHOLD_BASE_ACTIVE = False\n",
    "    threshold = 5.0\n",
    "\n",
    "    def __init__(self, df:pd.DataFrame, window_size:int = 60, discord_number = 476, method='mpx', measure='acc'):\n",
    "        self.measurement = measure\n",
    "        self.window_size = window_size\n",
    "        self.discord_number = discord_number\n",
    "        self.discord_dict = {}\n",
    "        self.discords = []\n",
    "        self.df = df\n",
    "        self.mp_method = method\n",
    "        self.curr_mp_dict = {}\n",
    "\n",
    "    def calculate_mp_multivariate_stumpy(self):\n",
    "        curr_mps, curr_indices = stumpy.mstump(self.df, self.window_size)\n",
    "        self.mps = curr_mps\n",
    "\n",
    "    def calculate_mp_seperately_mpx(self):\n",
    "        import matrixprofile as mp\n",
    "        mp_list = []\n",
    "        \n",
    "        for ft in self.df.columns:\n",
    "            inputSignal = self.df[ft].to_list()\n",
    "            matrix_profile = mp.compute(inputSignal, windows=self.window_size, threshold=0.95, n_jobs=4)\n",
    "            mp_list.append(matrix_profile['mp'])\n",
    "\n",
    "        self.mps = np.array(mp_list)\n",
    "    \n",
    "    def calculate_discords(self):\n",
    "        from collections import Counter\n",
    "        curr_mps_dict = dict()\n",
    "        curr_mps_dict = {f_idx: np.argsort(self.mps[idx])[::-1][:1000] for idx, f_idx in enumerate(self.df.columns)}\n",
    "        self.curr_mp_dict = {f_idx: np.sort(self.mps[idx])[::-1][:self.discord_number] for idx, f_idx in enumerate(self.df.columns)}\n",
    "\n",
    "        for idx, indices in curr_mps_dict.items():\n",
    "            # print(f'now processing current idx: {idx}') \n",
    "            indice_list = []\n",
    "            for indice in indices:\n",
    "                #get mp point window\n",
    "                indice_list.extend(list(range(indice, indice + self.window_size - 1)))\n",
    "            #sort the indices by count\n",
    "            if (MatrixProfileManager.THRESHOLD_BASE_ACTIVE == True):\n",
    "                sorted_discord_indexes = indice_list.copy()\n",
    "            else:\n",
    "                sorted_discords = sorted(Counter(indice_list).items(), key=lambda t:t[1], reverse=True)\n",
    "                sorted_discord_indexes = [elem[0] for elem in sorted_discords[:self.discord_number]]\n",
    "\n",
    "            self.discord_dict[idx] = sorted_discord_indexes\n",
    "\n",
    "    def majority_vote_discords(self):\n",
    "        from collections import Counter\n",
    "        overall_list = []\n",
    "        for ft, ids_list in self.discord_dict.items():\n",
    "            overall_list.extend(ids_list)\n",
    "\n",
    "        if (MatrixProfileManager.THRESHOLD_BASE_ACTIVE):\n",
    "            self.discords = list(set(overall_list))\n",
    "        else:\n",
    "            sorted_overall = (sorted(Counter(overall_list).items(), key=lambda t:t[1], reverse=True))\n",
    "            self.discords = [elem[0] for elem in sorted_overall[:self.discord_number]]\n",
    "\n",
    "\n",
    "    def obtain_y_vals(self):\n",
    "        df_idxs = list(range(0, len(MatrixProfileManager.global_df)))\n",
    "        for idx in self.discords:\n",
    "            try:\n",
    "                df_idxs.remove(idx)\n",
    "            except:\n",
    "                print(f\"idx : {idx} not found in global df indexes.\")\n",
    "  \n",
    "        \n",
    "        self.pred_df = pd.DataFrame()\n",
    "        self.pred_df['y_true'] = MatrixProfileManager.global_df[\"Label\"].copy()\n",
    "        self.pred_df[\"y_pred\"] = MatrixProfileManager.global_df[\"Label\"].copy()\n",
    "        \n",
    "        self.pred_df.iloc[df_idxs, 0] = 0\n",
    "        self.pred_df.iloc[self.discords, 0] = 1\n",
    "\n",
    "    def calculate_classification_report(self):\n",
    "        from sklearn.metrics import classification_report\n",
    "        if 'y_true' not in self.pred_df.columns:\n",
    "            raise ValueError('true vals not included in df')\n",
    "\n",
    "        if 'y_pred' not in self.pred_df.columns:\n",
    "            raise ValueError('pred vals not included in df')\n",
    "\n",
    "        self.creport = classification_report(self.pred_df[\"y_true\"].to_list(),\n",
    "                                             self.pred_df[\"y_pred\"].to_list(), output_dict=True)[\"1\"]\n",
    "\n",
    "    def get_f1_score(self):\n",
    "        if self.creport is None:\n",
    "            raise ValueError('Classification Report is not ready!')\n",
    "            \n",
    "        return self.creport['f1-score']\n",
    "\n",
    "    def get_mp_score(self):\n",
    "        #maximize this\n",
    "        return sum([sum(mp_score) for mp_score in self.curr_mp_dict.values()]) / len(self.curr_mp_dict.keys())\n",
    "\n",
    "    def calculate_cost(self):\n",
    "        if self.mp_method.lower() == 'mpx':\n",
    "            self.calculate_mp_seperately_mpx()\n",
    "        else:\n",
    "            self.calculate_mp_multivariate_stumpy()\n",
    "        \n",
    "        self.calculate_discords()\n",
    "        self.majority_vote_discords()\n",
    "        self.obtain_y_vals()\n",
    "        self.calculate_classification_report()\n",
    "\n",
    "        f1_score = self.get_f1_score()\n",
    "        mp_score = self.get_mp_score()\n",
    "        return mp_score, f1_score\n",
    "\n",
    "    def calculate_thresholded_discords(self):\n",
    "        from collections import Counter\n",
    "        curr_mps_dict = dict()\n",
    "        threshold = MatrixProfileManager.threshold\n",
    "        curr_mps_dict = {f_idx: np.where(self.mps[idx] > threshold)[0].tolist() for idx, f_idx in enumerate(self.df.columns)}\n",
    "        self.curr_mp_dict = {f_idx: np.sort(self.mps[idx])[::-1][:10] for idx, f_idx in enumerate(self.df.columns)}\n",
    "\n",
    "        for idx, indices in curr_mps_dict.items():\n",
    "            # print(f'now processing current idx: {idx}') \n",
    "            indice_list = []\n",
    "            for indice in indices:\n",
    "                #get mp point window\n",
    "                indice_list.extend(list(range(indice, indice + self.window_size - 1)))\n",
    "\n",
    "            if (MatrixProfileManager.THRESHOLD_BASE_ACTIVE):\n",
    "                self.discord_dict[idx] = list(set(indice_list))\n",
    "            else:\n",
    "                AssertionError(\"wrong func!\")\n",
    "\n",
    "    def calculate_threshold_based_cost(self):    \n",
    "        if self.mp_method.lower() == 'mpx':\n",
    "            self.calculate_mp_seperately_mpx()\n",
    "        else:\n",
    "            self.calculate_mp_multivariate_stumpy()\n",
    "\n",
    "        self.calculate_thresholded_discords()\n",
    "        self.majority_vote_discords()\n",
    "        self.obtain_y_vals()\n",
    "        self.calculate_classification_report()\n",
    "\n",
    "        f1_score = self.get_f1_score()\n",
    "        mp_score = self.get_mp_score()\n",
    "        return mp_score, f1_score\n",
    "\n",
    "\n",
    "class GeneticAlgo:\n",
    "    verbosity_level = 0\n",
    "    thresholded_mp = False\n",
    "    def __init__(self, df:pd.DataFrame, max_features:int, population_bag_size:int = 3, fitness = 'MP'):\n",
    "        print('Genetic Algorithm Process is ready to start')\n",
    "        self.df = df.copy()\n",
    "        self.y = df[[\"Label\"]]\n",
    "        self.X = df.drop([\"Label\"], axis = 1)\n",
    "        self.feature_map = {i : feat_name for i, feat_name in enumerate(self.X.columns)}\n",
    "        self.X.columns = list(range(0, len(self.X.columns)))\n",
    "        self.feature_number = max_features\n",
    "        self.pop_bag_size = population_bag_size\n",
    "        self.creport = None\n",
    "        self.eval_result = None\n",
    "        self.fitness_type = fitness\n",
    "        \n",
    "\n",
    "    def initialize_population(self):\n",
    "        self.population_bag = []\n",
    "        for _ in range(self.pop_bag_size):\n",
    "            #0 veya 1 atiyoruz feature pick or not pick, 1 olanlari appendliyoruz.\n",
    "            genes = [random.randrange(0,2) for _ in range(self.feature_number)]\n",
    "            gene_indexes = [idx for idx, f in enumerate(genes) if f == 1]\n",
    "            if (len(gene_indexes) == 0):\n",
    "                gene_indexes.append(random.randint(1,self.feature_number))\n",
    "\n",
    "            self.population_bag.append(self.X.iloc[:, gene_indexes])\n",
    "\n",
    "        return self.population_bag\n",
    "\n",
    "    def create_population(self, pop_bag) -> pd.DataFrame:\n",
    "        self.population_bag.clear()\n",
    "        for elem in pop_bag:\n",
    "            self.population_bag.append(self.X.iloc[:, elem])\n",
    "            \n",
    "        return self.population_bag\n",
    "\n",
    "    def fitness_function(self, individual:pd.DataFrame):\n",
    "        if (GeneticAlgo.thresholded_mp == True):\n",
    "            MatrixProfileManager.THRESHOLD_BASE_ACTIVE = True\n",
    "        else:\n",
    "            MatrixProfileManager.THRESHOLD_BASE_ACTIVE = False\n",
    "\n",
    "        mp_manager = MatrixProfileManager(individual, window_size=60, discord_number=1000, method='mpx', measure='f1')\n",
    "        if (GeneticAlgo.thresholded_mp == False):\n",
    "            cost, f1_score = mp_manager.calculate_cost()\n",
    "        elif (GeneticAlgo.thresholded_mp == True):\n",
    "            cost, f1_score = mp_manager.calculate_threshold_based_cost()\n",
    "            \n",
    "        if (GeneticAlgo.verbosity_level < 2):\n",
    "            print(f'processing solution: {individual.columns.to_list()}')\n",
    "            print(f\"f1-score is: {mp_manager.get_f1_score()}\")\n",
    "        #return f1score instead of cost in order to maximize f1-score:\n",
    "        \n",
    "        # return cost, f1_score\n",
    "        del mp_manager\n",
    "        return cost, f1_score\n",
    "\n",
    "    def eval_fit_population(self, pop_bag):\n",
    "        #This evaluation is based on minimizing the cost!\n",
    "        result = {}\n",
    "        fit_vals_lst = []\n",
    "        f1_score_lst = []\n",
    "        solutions = []\n",
    "        for individual in pop_bag:\n",
    "            if (type(individual) != pd.DataFrame):\n",
    "                assert(True)\n",
    "\n",
    "            cost, f1_sc = self.fitness_function(individual.copy())\n",
    "            fit_vals_lst.append(cost)\n",
    "            f1_score_lst.append(f1_sc)\n",
    "            solutions.append(individual.columns.to_list())\n",
    "            \n",
    "        result[\"fit_vals\"] = fit_vals_lst\n",
    "        result[\"f1-scores\"] = f1_score_lst \n",
    "        if self.fitness_type == \"MP\":\n",
    "            min_wgh = [abs(np.min(list(result['fit_vals'])) - i) for i in list(result['fit_vals'])]\n",
    "        else:\n",
    "            min_wgh = [abs(np.min(list(result['f1-scores'])) - i) for i in list(result['f1-scores'])]\n",
    "        \n",
    "        from scipy.special import logsumexp\n",
    "        result[\"fit_wgh\"]  = [i/logsumexp(min_wgh) for i in min_wgh]\n",
    "        result[\"solution\"] = np.array(solutions, dtype=list).tolist()\n",
    "        \n",
    "        self.eval_result = result.copy()\n",
    "        return result\n",
    "\n",
    "    def find_best(self, eval_result:dict)->dict:\n",
    "        # Best individual so far\n",
    "        best_fit = np.max(eval_result[\"fit_vals\"])\n",
    "        best_fit_index = eval_result[\"fit_vals\"].index(best_fit)\n",
    "        best_solution  = eval_result[\"solution\"][best_fit_index]\n",
    "        f1_sc = eval_result[\"f1-scores\"][best_fit_index]\n",
    "        print(f'best fit: {best_fit}\\nsolution: {best_solution}\\nf1Score: {f1_sc}')\n",
    "        return {'best_fit': best_fit, 'index' : best_fit_index,\n",
    "                 'solution': best_solution, 'f1-score' : f1_sc}\n",
    "\n",
    "    def pick_one(self, pop_bag):\n",
    "        \n",
    "        if self.eval_result is None:\n",
    "            eval_result = self.eval_fit_population(pop_bag)\n",
    "        else:\n",
    "            eval_result = self.eval_result\n",
    "\n",
    "        notPicked=True\n",
    "        cnt = 0\n",
    "        pickedSol = list()\n",
    "        while (notPicked == True):\n",
    "            rnIndex = random.randint(0, len(pop_bag)-1)\n",
    "            rnPick  = eval_result[\"fit_wgh\"][rnIndex]\n",
    "            r = random.random()\n",
    "            if  r <= rnPick:\n",
    "                pickedSol = eval_result[\"solution\"][rnIndex]\n",
    "                notPicked = False\n",
    "            if (cnt > 250):\n",
    "                pickedSol = eval_result[\"solution\"][rnIndex]\n",
    "                notPicked = False\n",
    "            cnt += 1\n",
    "\n",
    "        return pickedSol\n",
    "\n",
    "    def crossover(self, solA, solB):\n",
    "        \n",
    "        n     = len(solA)\n",
    "        child: list = []\n",
    "\n",
    "        num_els = random.randint(0, self.feature_number)\n",
    "        str_pnt = random.randint(0, max(0,n-3))\n",
    "        end_pnt = n if int(str_pnt+num_els) > n else int(str_pnt+num_els)\n",
    "\n",
    "        blockA = list(solA[str_pnt:end_pnt])\n",
    "        child = blockA.copy()\n",
    "\n",
    "        for elem in solB:\n",
    "            if len(child) >= num_els:\n",
    "                break\n",
    "            if elem not in blockA:\n",
    "                child.append(elem)  \n",
    "\n",
    "        if (len(child) < 1):\n",
    "            return solA\n",
    "\n",
    "        return child\n",
    "\n",
    "    def mutation(self,sol):\n",
    "        \n",
    "        # n = len(sol)\n",
    "        # pos_1 = random.randint(0,n-1)\n",
    "        # pos_2 = random.randint(0,n-1)\n",
    "        # result = self.swap(sol, pos_1, pos_2)\n",
    "        if (len(sol) > 2):\n",
    "            rd_idx = random.randint(0, len(sol) - 1)\n",
    "            del sol[rd_idx]\n",
    "        return sol\n",
    "\n",
    "    def swap(self,sol, posA, posB):\n",
    "        result = sol.copy()\n",
    "        elA = sol[posA]\n",
    "        elB = sol[posB]\n",
    "        result[posA] = elB\n",
    "        result[posB] = elA\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Genetic Algorithm Process is ready to start\n",
      "Generation 0 is started!\n",
      "processing solution: [0, 11, 12, 13, 14, 17, 19, 21, 23, 25, 26, 28, 29, 30, 33, 34, 35, 36, 37]\n",
      "f1-score is: 0.10783446029666868\n",
      "processing solution: [2, 9, 10, 12, 13, 14, 19, 20, 23, 24, 30, 32, 33, 35]\n",
      "f1-score is: 0.07421383647798743\n",
      "processing solution: [5, 9, 10, 12, 15, 16, 17, 18, 19, 21, 23, 24, 25, 28, 34, 35]\n",
      "f1-score is: 0.10783446029666868\n",
      "processing solution: [1, 2, 3, 7, 9, 15, 16, 17, 21, 23, 26, 31, 33, 37]\n",
      "f1-score is: 0.07421383647798743\n",
      "processing solution: [2, 6, 7, 8, 9, 11, 13, 15, 19, 20, 21, 22, 24, 26, 27, 29, 30, 31, 32, 33, 34, 36, 37]\n",
      "f1-score is: 0.10783446029666868\n",
      "processing solution: [1, 2, 3, 5, 7, 9, 10, 12, 13, 15, 16, 19, 21, 23, 24, 26, 27, 30, 31, 36, 37]\n",
      "f1-score is: 0.10783446029666868\n",
      "processing solution: [0, 1, 6, 8, 9, 10, 12, 13, 16, 17, 20, 21, 22, 24, 25, 27, 28, 29, 31, 32, 34, 35]\n",
      "f1-score is: 0.10783446029666868\n",
      "processing solution: [0, 1, 4, 5, 8, 9, 13, 14, 16, 17, 18, 20, 21, 24, 25, 29, 30, 33, 34, 35, 36, 37]\n",
      "f1-score is: 0.10783446029666868\n",
      "processing solution: [0, 1, 2, 7, 10, 11, 14, 15, 16, 17, 18, 23, 25, 26, 28, 30, 31, 32, 33, 36]\n",
      "f1-score is: 0.10783446029666868\n",
      "processing solution: [3, 7, 8, 10, 11, 13, 16, 17, 18, 20, 22, 23, 24, 29, 32, 34, 35]\n",
      "f1-score is: 0.10783446029666868\n",
      "best fit: 68.31479536178622\n",
      "solution: [0, 11, 12, 13, 14, 17, 19, 21, 23, 25, 26, 28, 29, 30, 33, 34, 35, 36, 37]\n",
      "f1Score: 0.10783446029666868\n",
      "Generation 1 is started!\n",
      "processing solution: [30, 31, 36, 37, 1, 2, 3, 5, 7, 9, 10]\n",
      "f1-score is: 0.07257072570725709\n",
      "processing solution: [0, 1, 2, 10, 11, 14, 15, 16, 17, 18, 23, 25, 26, 28, 30, 31, 32, 33, 36]\n",
      "f1-score is: 0.10783446029666868\n",
      "processing solution: [25, 28, 34, 35, 3, 7, 8, 10, 11, 13, 16, 17, 18, 20, 22]\n",
      "f1-score is: 0.10783446029666868\n",
      "processing solution: [12, 13, 14, 19, 20, 23, 24, 30, 32, 33, 35, 0, 1, 6, 8]\n",
      "f1-score is: 0.07190737355271176\n",
      "processing solution: [0, 1, 4, 5, 8, 9, 13, 14, 16, 17, 18, 20, 24, 25, 29, 30, 33, 34, 35, 36, 37]\n",
      "f1-score is: 0.10783446029666868\n",
      "processing solution: [34, 36, 37, 2, 3, 5, 7, 9, 10, 12, 13, 15, 16, 19, 21, 23, 24, 26, 27, 30, 31]\n",
      "f1-score is: 0.10783446029666868\n",
      "processing solution: [1, 2, 10, 11, 14, 15, 16, 17, 18, 23, 25, 26, 28, 30, 31, 32]\n",
      "f1-score is: 0.10783446029666868\n",
      "processing solution: [21, 23, 24, 25, 28, 34, 35, 1, 2, 3, 5, 7, 9, 10, 12, 13, 15, 16, 19, 26, 27, 30, 31, 37]\n",
      "f1-score is: 0.10783446029666868\n",
      "processing solution: [0, 1, 6, 8, 9, 10, 12, 13, 16, 17, 20, 21, 22, 24, 25, 27, 28, 29, 31, 32, 34, 35]\n",
      "f1-score is: 0.10783446029666868\n",
      "processing solution: [17, 18, 19, 21, 23, 24, 25, 28, 35, 0, 11, 12, 13]\n",
      "f1-score is: 0.10783446029666868\n",
      "best fit: 70.3367692850606\n",
      "solution: [17, 18, 19, 21, 23, 24, 25, 28, 35, 0, 11, 12, 13]\n",
      "f1Score: 0.10783446029666868\n",
      "Generation 2 is started!\n",
      "processing solution: [7, 9, 10, 12, 13, 15, 16, 19, 26, 27, 30, 31, 37, 0, 1, 4, 5, 8, 14, 17, 18, 20, 24, 25, 29, 33, 34, 35]\n",
      "f1-score is: 0.10783446029666868\n",
      "processing solution: [35, 1, 2, 3, 5, 7, 9, 10, 12, 13, 15, 16, 19, 26, 27, 30, 31, 37, 0, 4, 8, 14, 17, 18, 20, 24, 25, 33, 34, 36]\n",
      "f1-score is: 0.10783446029666868\n",
      "processing solution: [3, 5, 7]\n",
      "f1-score is: 0.07421383647798743\n",
      "processing solution: [26, 28, 30, 31, 32, 21, 23, 24, 25, 34, 35, 1, 2, 3, 5, 7, 10, 12, 13, 15, 16, 19, 27, 37]\n",
      "f1-score is: 0.10783446029666868\n",
      "processing solution: [17, 18, 19, 21, 23, 24, 25, 28, 35, 0, 12, 13]\n",
      "f1-score is: 0.10783446029666868\n",
      "processing solution: [23, 25, 26, 28, 30, 31, 32, 33, 36, 0, 1, 2, 10, 11, 15]\n",
      "f1-score is: 0.10783446029666868\n",
      "processing solution: [21, 22, 24, 25, 27, 28, 29, 31, 32, 34, 35, 0, 1, 2, 10, 11, 14, 15, 16, 17, 18, 23, 26, 30, 33, 36]\n",
      "f1-score is: 0.10783446029666868\n",
      "processing solution: [11, 13, 16, 17, 18, 20, 22, 19, 21, 23, 24, 25, 28, 35, 0]\n",
      "f1-score is: 0.10783446029666868\n",
      "processing solution: [28, 35, 0, 12, 13, 17, 18, 19, 21, 23, 24, 25]\n",
      "f1-score is: 0.10783446029666868\n",
      "processing solution: [35, 3, 7, 8, 10, 11, 13, 17, 18, 20, 22, 19, 21, 23, 24, 25, 28, 0, 12]\n",
      "f1-score is: 0.10783446029666868\n",
      "best fit: 73.70859025219004\n",
      "solution: [17, 18, 19, 21, 23, 24, 25, 28, 35, 0, 12, 13]\n",
      "f1Score: 0.10783446029666868\n",
      "Generation 3 is started!\n",
      "processing solution: [2, 10, 11, 15, 7, 9, 12, 13, 16, 19, 26, 27, 30, 31, 37, 0, 1, 5, 8, 14, 17, 18, 20]\n",
      "f1-score is: 0.10783446029666868\n",
      "processing solution: [12, 13, 15, 16, 19, 26, 27, 30]\n",
      "f1-score is: 0.10783446029666868\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/batuhanduyuler/opt/anaconda3/envs/tez_env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/batuhanduyuler/opt/anaconda3/envs/tez_env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/batuhanduyuler/opt/anaconda3/envs/tez_env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing solution: [26]\n",
      "f1-score is: 0.0\n",
      "processing solution: [26, 27, 30, 31, 37, 0, 4, 8, 14, 17, 18, 20, 24, 25, 33, 34, 36, 7, 9, 10, 12, 13, 15, 16, 19, 1, 5, 29, 35]\n",
      "f1-score is: 0.10783446029666868\n",
      "processing solution: [21, 23, 24, 35, 1, 2, 3, 5, 7, 9, 10, 12, 13, 15, 16, 19, 26, 27, 30, 31, 37, 0]\n",
      "f1-score is: 0.10783446029666868\n",
      "processing solution: [10, 11, 15, 26, 28, 30, 31, 32, 21, 23, 24, 25, 34, 35, 1, 2, 3, 5, 7, 12, 13, 16, 19, 27, 37]\n",
      "f1-score is: 0.10783446029666868\n",
      "processing solution: [21, 23, 24, 25, 34, 35, 1, 2, 5, 7, 10, 12, 13, 15, 16, 19, 27, 37, 22, 28, 29]\n",
      "f1-score is: 0.10783446029666868\n",
      "processing solution: [31, 32, 33, 36, 0, 1, 2, 10, 11, 15, 35, 3, 5, 7]\n",
      "f1-score is: 0.07190737355271176\n",
      "processing solution: [2, 10, 11, 14, 15, 16, 17, 18, 23, 26, 30, 33, 36, 35, 1, 3, 5, 7, 9, 12, 13, 19, 27, 31, 37, 0, 4, 8, 20, 24, 25, 34]\n",
      "f1-score is: 0.10783446029666868\n",
      "processing solution: [0, 1, 2, 10, 11, 14, 15, 16, 17, 18, 23, 26, 30]\n",
      "f1-score is: 0.07190737355271176\n",
      "best fit: 68.47169449177012\n",
      "solution: [21, 23, 24, 25, 34, 35, 1, 2, 5, 7, 10, 12, 13, 15, 16, 19, 27, 37, 22, 28, 29]\n",
      "f1Score: 0.10783446029666868\n",
      "Generation 4 is started!\n",
      "processing solution: [10, 11, 14, 15, 16, 17, 18, 23, 26, 27, 31, 37, 0, 4, 8, 20, 24, 25, 33, 34, 36, 7, 9, 12, 13, 19, 1]\n",
      "f1-score is: 0.10783446029666868\n",
      "processing solution: [20, 24, 25, 33, 34, 36, 7, 9, 10, 12, 13, 15]\n",
      "f1-score is: 0.07257072570725709\n",
      "processing solution: [2, 11, 14, 15, 16, 17, 18, 23, 26, 30, 33, 36, 35, 1, 3, 5, 7, 9, 12, 13, 19, 27, 31, 37, 0, 4, 8, 20, 24, 25, 34]\n",
      "f1-score is: 0.10783446029666868\n",
      "processing solution: [10, 11, 15, 35]\n",
      "f1-score is: 0.07454200884396715\n",
      "processing solution: [31, 32, 33, 36, 0, 1, 2, 10, 11, 15, 35, 3, 5, 7]\n",
      "f1-score is: 0.07190737355271176\n",
      "processing solution: [19, 26, 27]\n",
      "f1-score is: 0.10783446029666868\n",
      "processing solution: [7, 9, 12, 13]\n",
      "f1-score is: 0.06818181818181818\n",
      "processing solution: [16, 19, 26, 27, 30, 31, 37, 0, 1, 5, 8, 14, 17, 18, 20, 4, 24, 25, 33]\n",
      "f1-score is: 0.10783446029666868\n",
      "processing solution: [17, 18, 20, 24, 25, 33, 34, 36, 7, 9, 10, 12]\n",
      "f1-score is: 0.07257072570725709\n",
      "processing solution: [11, 15, 35, 3, 5, 7, 21, 23, 24]\n",
      "f1-score is: 0.07421383647798743\n",
      "best fit: 76.86565129462382\n",
      "solution: [19, 26, 27]\n",
      "f1Score: 0.10783446029666868\n",
      "\n",
      "\n",
      "**** Generations Over ****\n",
      "\n",
      "Best Fitness: 76.86565129462382\n",
      "Best Solution: [19, 26, 27]\n",
      "F1-Score: 0.10783446029666868\n"
     ]
    }
   ],
   "source": [
    "import mp_genetic_utils\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "import random as rnd\n",
    "MatrixProfileManager.THRESHOLD_BASE_ACTIVE = True\n",
    "MatrixProfileManager.global_df = df.copy()\n",
    "MatrixProfileManager.threshold = 8\n",
    "GeneticAlgo.thresholded_mp = True\n",
    "genetic_algo = GeneticAlgo(df.copy(), max_features=38, population_bag_size=10, fitness=\"F1\")\n",
    "pop_bag = genetic_algo.initialize_population()\n",
    "generation_number = 5\n",
    "for generation in range(generation_number):\n",
    "    print(f\"Generation {generation} is started!\")\n",
    "    \n",
    "    res = genetic_algo.eval_fit_population(pop_bag)\n",
    "    best_fit, _, best_solution, f1_score = genetic_algo.find_best(res).values()\n",
    "    \n",
    "    if (generation == 0):\n",
    "        best_fit_global      = best_fit\n",
    "        best_solution_global = best_solution\n",
    "        best_f1_global = f1_score\n",
    "    else:\n",
    "        if (f1_score >= best_f1_global):\n",
    "            best_fit_global      = best_fit\n",
    "            best_solution_global = best_solution\n",
    "            best_f1_global = f1_score\n",
    "\n",
    "    new_pop_bag = []\n",
    "    for i in range(len(genetic_algo.population_bag)):\n",
    "                # Pick 2 parents from the bag\n",
    "        pA = genetic_algo.pick_one(pop_bag)\n",
    "        pB = genetic_algo.pick_one(pop_bag)\n",
    "        new_element = pA\n",
    "            # Crossover the parents\n",
    "        if rnd.random() <= 0.87:\n",
    "            new_element = genetic_algo.crossover(pA, pB)\n",
    "            # Mutate the child\n",
    "        if rnd.random() <= 0.5:\n",
    "            new_element = genetic_algo.mutation(new_element) \n",
    "        new_pop_bag.append(new_element)\n",
    "            # Set the new bag as the population bag\n",
    "    pop_bag = genetic_algo.create_population(new_pop_bag)\n",
    "\n",
    "print(\"\\n\\n**** Generations Over ****\\n\")\n",
    "print(f\"Best Fitness: {best_fit_global}\")\n",
    "print(f\"Best Solution: {best_solution_global}\")\n",
    "print(f\"F1-Score: {f1_score}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.randint(0, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_list = list(range(0, len(MatrixProfileManager.global_df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "635"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mp_manager.discords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Genetic Algorithm Process is ready to start\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Genetic Algorithm Process is ready to start\n",
      "threshold based discords\n",
      "threshold based discords\n",
      "threshold based discords\n",
      "threshold based discords\n",
      "threshold based discords\n"
     ]
    }
   ],
   "source": [
    "gA = GeneticAlgo(df.copy(), max_features=10, population_bag_size=5, fitness=\"F1\")\n",
    "first_pop = gA.initialize_population()\n",
    "\n",
    "MatrixProfileManager.THRESHOLD_BASE_ACTIVE = True\n",
    "MatrixProfileManager.global_df = df.copy()\n",
    "MatrixProfileManager.threshold = 5\n",
    "\n",
    "for pop in first_pop:\n",
    "    mp_deneme_manager = MatrixProfileManager(pop, window_size=60, discord_number=1000, method='mpx', measure='f1')\n",
    "    cost, f1_score = mp_deneme_manager.calculate_threshold_based_cost()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tez_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "284da31d2e08a0f3b9298738c7f12e5d4fd5ac3878570c49a01eae1702b4dd5d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
